# Indian Sign Language Smart Communication Tool

A real-time **Indian Sign Language (ISL) recognition system** that converts hand gestures into **text and speech** using Computer Vision and Machine Learning. The project supports both **static alphabet signs (Aâ€“Z)** and **dynamic word-level signs (Hello, Thank You)**.

---

## ğŸ¯ Project Features

* ğŸ–ï¸ Real-time hand tracking using **MediaPipe**
* ğŸ”¤ Static sign recognition (Aâ€“Z)
* ğŸ¥ Dynamic sign recognition (Hello, Thank You)
* ğŸ“ Sentence builder with space & backspace logic
* ğŸ”Š Online Text-to-Speech (Google TTS)
* ğŸ§  Trained ML models included using **Git LFS**

---

## ğŸ› ï¸ Tech Stack

* Python
* OpenCV
* MediaPipe
* NumPy, Pandas
* Scikit-learn
* TensorFlow / Keras (for dynamic signs)
* gTTS (Online Text-to-Speech)

---

## ğŸ“‚ Project Structure

```
sign_lang_smart_comm/
â”œâ”€â”€ dataset/                 # Static alphabet CSV datasets (Aâ€“Z)
â”œâ”€â”€ dynamic_dataset/         # Dynamic sign .npy datasets
â”‚   â”œâ”€â”€ hello/
â”‚   â””â”€â”€ thank_you/
â”œâ”€â”€ train_model.py           # Static model training
â”œâ”€â”€ train_dynamic_model.py   # Dynamic model training
â”œâ”€â”€ sentence_builder.py      # Real-time recognition + speech
â”œâ”€â”€ isl_alphabet_model.pkl   # Trained static model
â”œâ”€â”€ dynamic_sign_model.h5    # Trained dynamic model
â”œâ”€â”€ .gitattributes           # Git LFS tracking
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âœ‹ Static Sign Recognition (Aâ€“Z)

### Dataset

* Each alphabet (Aâ€“Z) has its own folder
* Data stored as `data.csv`
* Each row contains **126 features** (21 landmarks Ã— 3 Ã— 2 hands)

### Training

* All CSV files are merged
* Labels assigned per alphabet
* Model trained using Scikit-learn
* Saved as:

  ```
  isl_alphabet_model.pkl
  ```

---

## ğŸ¥ Dynamic Sign Recognition (Hello & Thank You)

### Dataset Creation

* Short videos recorded for each word
* MediaPipe extracts landmarks **per frame**
* Each frame â†’ 126 features
* Frames combined into fixed-length sequences
* Saved as `.npy` files

Example shape:

```
(sequence_length, 126)
```

### Training

* `.npy` sequences loaded
* Labels assigned (hello / thank_you)
* Sequence-based model (LSTM)
* Saved as:

  ```
  dynamic_sign_model.h5
  dynamic_sign_model.pkl
  ```

---


https://github.com/user-attachments/assets/52a8b8ed-b645-4b15-99c0-eb7084307ea5


## ğŸ”„ Real-Time Logic

* **Low motion** â†’ Static model (letters)
* **High motion** â†’ Dynamic model (words)
* Static letters form sentences
* Dynamic words are displayed/spoken directly

---

## ğŸ”Š Text-to-Speech

* Uses **online Google Text-to-Speech (gTTS)**
* Press **S** to speak the sentence
* Temporary audio files auto-deleted

---

## âŒ¨ï¸ Controls

| Key | Action                            |
| --- | --------------------------------- |
| q   | Quit application                  |
| s   | Speak sentence                    |
| b   | Backspace (delete last character) |

---

## ğŸ“¦ Model Files & Git LFS

Large files are tracked using **Git LFS**:

```
*.pkl
*.h5
```

Make sure Git LFS is installed before cloning:

```
git lfs install
git lfs pull
```

---

## ğŸš€ How to Run

```bash
pip install -r requirements.txt
python sentence_builder.py
```

---

## ğŸ§  Outcome

This system enables **real-time ISL to speech translation**, making communication more accessible for the hearing-impaired and muted community.


---

## ğŸ‘©â€ğŸ’» Author

**Hetvi Pandav**
BE â€“ Artificial Intelligence & Machine Learning


https://github.com/user-attachments/assets/0291d2be-7cc2-4521-8bce-1b288516b94a


---

â­ If you found this project useful, feel free to star the repository!



